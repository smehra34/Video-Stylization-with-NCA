{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import json \n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def tile2d(a, w=None):\n",
    "    a = np.asarray(a)\n",
    "    if w is None:\n",
    "        w = int(np.ceil(np.sqrt(len(a))))\n",
    "    th, tw = a.shape[1:3]\n",
    "    pad = (w - len(a)) % w\n",
    "    a = np.pad(a, [(0, pad)] + [(0, 0)] * (a.ndim - 1), 'constant')\n",
    "    h = len(a) // w\n",
    "    a = a.reshape([h, w] + list(a.shape[1:]))\n",
    "    a = np.rollaxis(a, 2, 1).reshape([th * h, tw * w] + list(a.shape[4:]))\n",
    "    return a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def torch_model_to_np(nca_model, has_bias=False):\n",
    "    # read in parameters excluding the first 3 weights which correspond to the sobel and laplacian filters\n",
    "    params = list(nca_model.parameters())[3:]\n",
    "    print(len(params))\n",
    "    \n",
    "    for name, param in nca_model.named_parameters():\n",
    "        print(name)\n",
    "        \n",
    "    layers = []\n",
    "\n",
    "    i = 0\n",
    "    layer1_weight = params[i][:, :, 0, 0].detach().cpu().numpy()\n",
    "    i += 1\n",
    "    layer1_bias = params[i][:, None].detach().cpu().numpy()\n",
    "    i += 1\n",
    "\n",
    "    print(f\"{layer1_weight.shape=}, {layer1_bias.shape=}\")\n",
    "    print(f\"{params[i].shape=}\")\n",
    "    \n",
    "    layer1_params = np.concatenate([layer1_weight, layer1_bias], axis=1).T\n",
    "    layer1_params = layer1_params[None, ...]\n",
    "    # layer_params[:, -1] is for bias\n",
    "    # layer_params[:, -3:-1] is for the positional encoding\n",
    "\n",
    "    layers.append(layer1_params)\n",
    "\n",
    "    if has_bias:\n",
    "        layer2_weight = params[i][:, :, 0, 0].detach().cpu().numpy()\n",
    "        i += 1\n",
    "        layer2_bias = params[i][:, None].detach().cpu().numpy()\n",
    "        i += 1\n",
    "        layer2_params = np.concatenate([layer2_weight, layer2_bias], axis=1).T\n",
    "        layer2_params = layer2_params[None, ...]\n",
    "    else:\n",
    "        layer2_weight = params[i][:, :, 0, 0].detach().cpu().numpy().T\n",
    "        i += 1\n",
    "        layer2_params = layer2_weight[None, ...]\n",
    "\n",
    "    layers.append(layer2_params)\n",
    "\n",
    "    return layers\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def torch_model_list_to_np(model_paths, has_bias=True):\n",
    "    model = torch.load(model_paths[0]).eval().cpu()\n",
    "    np_params = torch_model_to_np(model, has_bias=has_bias)\n",
    "    for model_path in model_paths[1:]:\n",
    "        model = torch.load(model_path).eval().cpu()\n",
    "        params = torch_model_to_np(model, has_bias=has_bias)\n",
    "        for i, p in enumerate(params):\n",
    "            np_params[i] = np.concatenate([np_params[i], p], axis=0)\n",
    "\n",
    "    return np_params\n",
    "\n",
    "\n",
    "def export_np_models_to_json(np_models, metadata):\n",
    "    '''Exoprt numpy models in a form that ca.js can read.'''\n",
    "    models_js = {'model_names': metadata['model_names'], 'layers': []}\n",
    "    for i, layer in enumerate(np_models):\n",
    "        shape = layer[0].shape\n",
    "        layer = np.array(layer)  # shape: [n, c_in, fc_dim]\n",
    "        \n",
    "        s = layer.shape\n",
    "        layer = np.pad(layer, ((0, 0), (0, 0), (0, (4 - s[2]) % 4)), mode='constant')\n",
    "        layer = layer.reshape(s[0], s[1], -1, 4)  # [n, 4xc_in, fc_dim // 4, 4]\n",
    "        n, ht, wt = layer.shape[:3]\n",
    "        w = 1\n",
    "        while w < n and w * wt < (n + w - 1) // w * ht:\n",
    "            w += 1\n",
    "        layer = tile2d(layer, w)\n",
    "        layout = (w, (n + w - 1) // w)\n",
    "\n",
    "        scale = float(layer.max() - layer.min())\n",
    "        center = float(-layer.min() / scale)\n",
    "        layer = layer - layer.min()\n",
    "        layer = layer / scale\n",
    "        layer_flatten = layer.flatten()\n",
    "\n",
    "        layer = np.round(layer * 255.0)\n",
    "        layer = np.uint8(layer.clip(0, 255))\n",
    "\n",
    "        layer_js = {\n",
    "            'scale': scale,\n",
    "            'center': center,\n",
    "            'data_flatten': list(map(float, list(layer_flatten))),\n",
    "            'data_shape': layer.shape,\n",
    "            'shape': shape,\n",
    "            'layout': layout,\n",
    "            'pos_emb': (i == 0) and metadata['pos_emb'],\n",
    "            'edge_conditioning': (i == 0) and metadata['edge_conditioning'],\n",
    "            'bias': True,\n",
    "\n",
    "        }\n",
    "        models_js['layers'].append(layer_js)\n",
    "    return models_js\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_OUTDIR = '../docs/data/vec_field_models/large'\n",
    "STYLE_IMG_OUTDIR = '../docs/images/texture'\n",
    "EXPERIMENTS_DIR = 'remote_experiments/experiments'\n",
    "METADATA_JSON_PATH = '../docs/data/metadata.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "cond_layer.sobel_x.weight\n",
      "cond_layer.sobel_y.weight\n",
      "cond_layer.laplacian.weight\n",
      "w1.weight\n",
      "w1.bias\n",
      "w2.weight\n",
      "w2.bias\n",
      "layer1_weight.shape=(96, 51), layer1_bias.shape=(96, 1)\n",
      "params[i].shape=torch.Size([12, 96, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "style_name = 'gta5'\n",
    "experiment_name = 'experiment_35'\n",
    "\n",
    "model_path = f'{EXPERIMENTS_DIR}/{experiment_name}/models/model_1999.pth'\n",
    "style_img_path = f'{EXPERIMENTS_DIR}/{experiment_name}/setup_images/target_appearance_image.png'\n",
    "\n",
    "np_params = torch_model_list_to_np([model_path], True)\n",
    "js_models = export_np_models_to_json(np_params, {'model_names': ['test'], 'edge_conditioning': True, 'pos_emb': False})\n",
    "json.dump(js_models, open(f\"{MODEL_OUTDIR}/{style_name}.json\", 'w'))\n",
    "\n",
    "shutil.copyfile(style_img_path, f\"{STYLE_IMG_OUTDIR}/{style_name}.jpg\")\n",
    "\n",
    "\n",
    "with open(METADATA_JSON_PATH) as f:\n",
    "    md = json.load(f)\n",
    "\n",
    "md['texture_names'] = list(set(md['texture_names'] + [style_name]))\n",
    "\n",
    "with open(METADATA_JSON_PATH, 'w', encoding='utf-8') as f:\n",
    "    json.dump(md, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
