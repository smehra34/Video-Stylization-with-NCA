{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def tile2d(a, w=None):\n",
    "    a = np.asarray(a)\n",
    "    if w is None:\n",
    "        w = int(np.ceil(np.sqrt(len(a))))\n",
    "    th, tw = a.shape[1:3]\n",
    "    pad = (w - len(a)) % w\n",
    "    a = np.pad(a, [(0, pad)] + [(0, 0)] * (a.ndim - 1), 'constant')\n",
    "    h = len(a) // w\n",
    "    a = a.reshape([h, w] + list(a.shape[1:]))\n",
    "    a = np.rollaxis(a, 2, 1).reshape([th * h, tw * w] + list(a.shape[4:]))\n",
    "    return a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def torch_model_to_np(nca_model, has_bias=False):\n",
    "    params = list(nca_model.parameters())\n",
    "\n",
    "    layers = []\n",
    "\n",
    "    i = 0\n",
    "    layer1_weight = params[i][:, :, 0, 0].detach().cpu().numpy()\n",
    "    i += 1\n",
    "    layer1_bias = params[i][:, None].detach().cpu().numpy()\n",
    "    i += 1\n",
    "    layer1_params = np.concatenate([layer1_weight, layer1_bias], axis=1).T\n",
    "    layer1_params = layer1_params[None, ...]\n",
    "    # layer_params[:, -1] is for bias\n",
    "    # layer_params[:, -3:-1] is for the positional encoding\n",
    "\n",
    "    layers.append(layer1_params)\n",
    "\n",
    "    if has_bias:\n",
    "        layer2_weight = params[i][:, :, 0, 0].detach().cpu().numpy()\n",
    "        i += 1\n",
    "        layer2_bias = params[i][:, None].detach().cpu().numpy()\n",
    "        i += 1\n",
    "        layer2_params = np.concatenate([layer2_weight, layer2_bias], axis=1).T\n",
    "        layer2_params = layer2_params[None, ...]\n",
    "    else:\n",
    "        layer2_weight = params[i][:, :, 0, 0].detach().cpu().numpy().T\n",
    "        i += 1\n",
    "        layer2_params = layer2_weight[None, ...]\n",
    "\n",
    "    layers.append(layer2_params)\n",
    "\n",
    "    return layers\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def torch_model_list_to_np(model_paths, has_bias=True):\n",
    "    model = torch.load(model_paths[0]).eval().cpu()\n",
    "    np_params = torch_model_to_np(model, has_bias=has_bias)\n",
    "    for model_path in model_paths[1:]:\n",
    "        model = torch.load(model_path).eval().cpu()\n",
    "        params = torch_model_to_np(model, has_bias=has_bias)\n",
    "        for i, p in enumerate(params):\n",
    "            np_params[i] = np.concatenate([np_params[i], p], axis=0)\n",
    "\n",
    "    return np_params\n",
    "\n",
    "\n",
    "def export_np_models_to_json(np_models, metadata):\n",
    "    '''Exoprt numpy models in a form that ca.js can read.'''\n",
    "    models_js = {'model_names': metadata['model_names'], 'layers': []}\n",
    "    for i, layer in enumerate(np_models):\n",
    "        shape = layer[0].shape\n",
    "        layer = np.array(layer)  # shape: [n, c_in, fc_dim]\n",
    "        if i == 0:\n",
    "            c = 1\n",
    "            if metadata['pos_emb']:\n",
    "                c += 2\n",
    "            # Replaced with np equiv. for time being so this works internally.\n",
    "            # layer[:,:-1] = rearrange(layer[:,:-1], 'n (h c) w -> n (c h) w', c=fixed_filter_n)\n",
    "            s = layer[:, :-c].shape\n",
    "            # layer[:, :-c] = (layer[:, :-c]\n",
    "            #                  .reshape(s[0], -1, fixed_filter_n, s[2])\n",
    "            #                  .transpose(0, 2, 1, 3) # [n, 4, c_in, fc_dim]\n",
    "            #                  .reshape(s))\n",
    "        # layer = rearrange(layer, 'n h (w c) -> h (n w) c', c=4)\n",
    "        # N.B. this 4 is not the fixed filter number, but a webgl implementation detail.\n",
    "        # Pad when number of channels is not a multiple of 4.\n",
    "        s = layer.shape\n",
    "        layer = np.pad(layer, ((0, 0), (0, 0), (0, (4 - s[2]) % 4)), mode='constant')\n",
    "        layer = layer.reshape(s[0], s[1], -1, 4)  # [n, 4xc_in, fc_dim // 4, 4]\n",
    "        n, ht, wt = layer.shape[:3]\n",
    "        w = 1\n",
    "        while w < n and w * wt < (n + w - 1) // w * ht:\n",
    "            w += 1\n",
    "        layer = tile2d(layer, w)\n",
    "        layout = (w, (n + w - 1) // w)\n",
    "\n",
    "        scale = float(layer.max() - layer.min())\n",
    "        center = float(-layer.min() / scale)\n",
    "        layer = layer - layer.min()\n",
    "        layer = layer / scale\n",
    "        layer_flatten = layer.flatten()\n",
    "\n",
    "        layer = np.round(layer * 255.0)\n",
    "        layer = np.uint8(layer.clip(0, 255))\n",
    "\n",
    "        layer_js = {\n",
    "            'scale': scale,\n",
    "            'center': center,\n",
    "            'data_flatten': list(map(float, list(layer_flatten))),\n",
    "            'data_shape': layer.shape,\n",
    "            'shape': shape,\n",
    "            'layout': layout,\n",
    "            'pos_emb': (i == 0) and metadata['pos_emb'],\n",
    "            'bias': True,\n",
    "\n",
    "        }\n",
    "        models_js['layers'].append(layer_js)\n",
    "    return models_js\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Images: 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 45/45 [00:06<00:00,  6.93it/s]\n"
     ]
    }
   ],
   "source": [
    "# Converting vector field motion models\n",
    "\n",
    "image_path = \"data/VectorFieldMotion/Appearance/\"\n",
    "img_names = sorted(os.listdir(image_path))\n",
    "img_names = [s for s in img_names if \".jpg\" in s or \".png\" in s]\n",
    "print(f\"Number of Images: {len(img_names)}\")\n",
    "models_path = \"out/VectorFieldMotionS/\"\n",
    "    \n",
    "motion_names = [\n",
    "    '0', '270', 'grad_0_0', 'grad_0_90',\n",
    "    'circular', 'diverge', 'converge', 'hyperbolic',\n",
    "    '2block_x', '2block_y', '3block', '4block',\n",
    "]\n",
    "\n",
    "# img_names = ['flames.png']\n",
    "for img_name in tqdm(img_names):\n",
    "    img_name = img_name.split(\".\")[0]\n",
    "    model_pth_paths = [] \n",
    "    for motion_name in motion_names:\n",
    "        model_pth_paths.append(f\"{models_path}/{img_name}/{motion_name}/model.pth\")\n",
    "        \n",
    "    np_params = torch_model_list_to_np(model_pth_paths, True)\n",
    "    js_models = export_np_models_to_json(np_params, {'model_names': motion_names, 'pos_emb': True})\n",
    "    json.dump(js_models, open(f\"out/json_models/VectorFieldMotionS/{img_name}.json\", 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dynca_env",
   "language": "python",
   "name": "dynca_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
